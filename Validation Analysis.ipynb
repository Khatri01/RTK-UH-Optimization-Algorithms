{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538cf2c2-1f6e-4c6c-b1c8-4592d483100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from math import pi\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cacfc3-2117-40f1-a203-9bede742646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Optimization_RTK_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024aa562-cb82-4c8f-9bfa-fdcaab7ca9d3",
   "metadata": {},
   "source": [
    "## Loading Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9230dcb8-35e1-4e17-8b88-7963a4590eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Parameter Values for Each Sheet (across all events):\n",
      "          R1        R2        R3      T1      T2       T3     K1      K2  \\\n",
      "DE  0.003811  0.013430  0.008374  3000.0  7800.0  12300.0  1.382  2.4345   \n",
      "SA  0.004393  0.010908  0.008173  3000.0  5700.0  11700.0  1.477  2.5760   \n",
      "\n",
      "       K3  \n",
      "DE  5.461  \n",
      "SA  5.224  \n"
     ]
    }
   ],
   "source": [
    "# Suppress matplotlib INFO messages\n",
    "logging.getLogger('matplotlib.category').setLevel(logging.WARNING)\n",
    "\n",
    "# List of Excel file names (each representing an event)\n",
    "# List of Excel file names (each representing an event)\n",
    "files = [\n",
    "    #'RTK_Parameters_all_algorithms_Ro_constraint_E1_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E2_CCW.xlsx', \n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E3_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E4_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E5_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E6_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E7_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E8_CCW.xlsx',\n",
    "    'RTK_Parameters_all_algorithms_Ro_constraint_E9_CCW.xlsx',\n",
    "] \n",
    "\n",
    "# List of sheets and parameters to read\n",
    "#sheets = [ 'CMA-ES','DE', 'GA', 'SA', 'PSO']\n",
    "#sheets = ['DE', 'GA', 'SA', 'CMA-ES']\n",
    "#sheets = ['DE', 'SA', 'CMA-ES']\n",
    "sheets = ['DE', 'SA']\n",
    "\n",
    "#sheets = ['CMA-ES']\n",
    "#sheets = ['DE']\n",
    "#sheets = ['GA']\n",
    "#sheets = ['SA']\n",
    "#sheets = ['PSO']\n",
    "\n",
    "parameters = ['R1', 'R2', 'R3', 'T1', 'T2', 'T3', 'K1', 'K2', 'K3']\n",
    "algorithms = sheets\n",
    "\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "# Initialize a dictionary to hold data aggregated by sheet\n",
    "# Here we combine the data for each parameter from each file, separately for each sheet.\n",
    "data_by_sheet = {sheet: {param: [] for param in parameters} for sheet in sheets}\n",
    "for file in files:\n",
    "    for sheet in sheets:\n",
    "        df = pd.read_excel(file, sheet_name=sheet)\n",
    "        for param in parameters:\n",
    "            data_by_sheet[sheet][param].extend(df[param].tolist())\n",
    "\n",
    "# Compute the median for each parameter in each sheet\n",
    "sheet_averages = {}\n",
    "for sheet in sheets:\n",
    "    sheet_averages[sheet] = {}\n",
    "    for param in parameters:\n",
    "        values = data_by_sheet[sheet][param]\n",
    "        # Compute the average (mean) of the values\n",
    "        #sheet_averages[sheet][param] = np.mean(values)\n",
    "        sheet_averages[sheet][param] = np.median(values)\n",
    "\n",
    "# Convert the results into a DataFrame for an easy-to-read table.\n",
    "# The resulting DataFrame will have the sheets as rows and the parameters as columns.\n",
    "avg_df = pd.DataFrame(sheet_averages).T\n",
    "print(\"Average Parameter Values for Each Sheet (across all events):\")\n",
    "print(avg_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8cfe5-3703-4caf-af5b-4bab2e62e86c",
   "metadata": {},
   "source": [
    "### 1 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4703a5a1-dbd3-4796-aa49-91f931469305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the second DataFrame with weights for DE, SA, GA, and PSO\n",
    "average_final  = pd.DataFrame({\n",
    "    'Algorithm': ['CMA-ES'], #CMA_ES','SA', 'GA', 'PSO'\n",
    "    'Rank_Weights': [1]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794511bf-12ec-4e60-9a1c-7a1f457fc775",
   "metadata": {},
   "source": [
    "### 5 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a0157d9e-c660-4d82-a546-ed8fc2323222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the second DataFrame with weights for DE, SA, GE, and PSO\n",
    "average_final= pd.DataFrame({\n",
    "    'Algorithm': ['DE','SA', 'CMA-ES', 'GA', 'PSO'],\n",
    "    'Rank_Weights': [0.333333, 0.266667, 0.2, 0.133333, 0.066667]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e1339-0b96-4c2f-85d4-776c5a5fc4a8",
   "metadata": {},
   "source": [
    "### 4 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f53fcd76-f7a5-4e24-a079-735927ba583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the second DataFrame with weights for DE, SA, GE, and PSO\n",
    "average_final = pd.DataFrame({\n",
    "    'Algorithm': ['DE', 'SA', 'CMA-ES', 'GA'],\n",
    "    'Rank_Weights': [0.4, 0.3, 0.2, 0.1]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fd83d-3be8-47e3-84e6-b63bcf5f83fb",
   "metadata": {},
   "source": [
    "### 3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ddc4fb0a-86fd-4b3c-9878-70c1c5d156ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first DataFrame with weights for only DE and SA\n",
    "average_final  = pd.DataFrame({\n",
    "    'Algorithm': ['DE','SA', 'CMA-ES'],\n",
    "    'Rank_Weights': [0.5, 0.333333,0.166667]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc858c0-8e52-428a-8f4d-306d166bf367",
   "metadata": {},
   "source": [
    "### 2 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4e538bef-1ffd-4bb4-a59a-c7bc3ae6494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first DataFrame with weights for only DE and SA\n",
    "average_final = pd.DataFrame({\n",
    "    'Algorithm': ['DE', 'SA'],\n",
    "    'Rank_Weights': [0.666667, 0.333333]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8470542-e234-40b2-a2c3-711e2a94aa75",
   "metadata": {},
   "source": [
    "## Event to validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "be8dc38b-7404-4df3-9045-3dfffbd6ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = './Tamucc_event_4.xlsx'\n",
    "file_path_validation = './CCW_event_1.xlsx'\n",
    "data=pd.read_excel(file_path_validation, skiprows=0)\n",
    "rainfall= data.iloc[:,2].dropna().tolist() \n",
    "obs_rdii = data.iloc[:,1].tolist() \n",
    "delta_t = 600 #in sec ( for 10 min time step)\n",
    "area_acres= 491.153"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c640eb2-0b1f-4d1b-bbc9-c9732e376eca",
   "metadata": {},
   "source": [
    "## Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd842f79-f434-4f81-8b38-fc49ee647d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' First Execute the Function defination'''\n",
    "\n",
    "\n",
    "predicted_flows, weighted_flow, metrics, final_weighted_score= RDII_all_algorithms_plot_with_weights_validation(\n",
    "    avg_df,               # avg_df: DataFrame with average parameters\n",
    "    average_final  , #df containing algorithms and weights\n",
    "    delta_t, \n",
    "    rainfall, \n",
    "    \n",
    "    area_acres, \n",
    "    obs_rdii, \n",
    "    weight_type='Rank_Weights'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c063b-29b4-4296-9948-702370543db2",
   "metadata": {},
   "source": [
    "## Function defination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eaaa6e4-f52e-4a72-8bcc-c40332536e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RDII_all_algorithms_plot_with_weights_validation(avg_df, Rank_weight, delta_t, rainfall, Area, obs_rdii=None, weight_type='Linear_Weights', plot_name=None):\n",
    "    \"\"\"\n",
    "    Use the average parameter values (from avg_df) for each algorithm (e.g. 'DE', 'GA', etc.)\n",
    "    along with the corresponding weights (from Rank_weight) to compute the weighted RDII flow.\n",
    "    Then plot the weighted flow against the observed RDII (padding the shorter array if necessary)\n",
    "    and display the evaluation metrics along with a composite final score.\n",
    "\n",
    "    Parameters:\n",
    "      avg_df: DataFrame indexed by algorithm (e.g. 'DE', 'GA', etc.) containing average values for\n",
    "              the parameters: R1, T1, K1, R2, T2, K2, R3, T3, K3.\n",
    "      Rank_weight: DataFrame containing weights for each algorithm. Must include a column for the given weight_type.\n",
    "      delta_t: Time step in seconds.\n",
    "      rainfall: Rainfall time series (in inches).\n",
    "      Area: Catchment area in acres.\n",
    "      obs_rdii: Observed RDII time series (optional).\n",
    "      weight_type: Type of weights to use ('Linear_Weights', 'Rank_Weights', or 'Softmax_Weights').\n",
    "      plot_name: Optional string for the filename to save the figure (e.g., \"figure.png\").\n",
    "      \n",
    "    Returns:\n",
    "      predicted_flows_all_algorithms: Dictionary with predicted flows (per algorithm).\n",
    "      weighted_flow: Final weighted RDII flow time series.\n",
    "      metrics: Dictionary with RMSE, R², PBIAS, and NSE (if obs_rdii is provided), else None.\n",
    "      final_weighted_score: Composite score for the weighted flow (if obs_rdii is provided), else None.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # --- Helper functions for metrics transformation ---\n",
    "    def calculate_metrics(simulated, observed):\n",
    "        simulated = np.array(simulated)\n",
    "        observed = np.array(observed)\n",
    "        rmse = np.sqrt(mean_squared_error(observed, simulated))\n",
    "        r2 = r2_score(observed, simulated)\n",
    "        pbias = 100 * np.sum(observed - simulated) / np.sum(observed)\n",
    "        numerator = np.sum((observed - simulated) ** 2)\n",
    "        denominator = np.sum((observed - np.mean(observed)) ** 2)\n",
    "        nse = 1 - (numerator / denominator)\n",
    "        return {'RMSE': rmse, 'R2': r2, 'PBIAS': pbias, 'NSE': nse}\n",
    "    \n",
    "    def transform_metrics(metrics):\n",
    "        f_rmse = 1 / (1 + metrics['RMSE'])\n",
    "        f_pbias = max(0, 1 - abs(metrics['PBIAS']) / 100)\n",
    "        f_r2 = max(0, min(metrics['R2'], 1))\n",
    "        nse = metrics['NSE']\n",
    "        if nse < -1:\n",
    "            f_nse = 0\n",
    "        elif nse > 1:\n",
    "            f_nse = 1\n",
    "        else:\n",
    "            f_nse = (nse + 1) / 2\n",
    "        return {'f_RMSE': f_rmse, 'f_R2': f_r2, 'f_PBIAS': f_pbias, 'f_NSE': f_nse}\n",
    "    \n",
    "    def composite_score(metrics):\n",
    "        transformed = transform_metrics(metrics)\n",
    "        score = (transformed['f_RMSE'] + transformed['f_R2'] + transformed['f_PBIAS'] + transformed['f_NSE']) / 4\n",
    "        return score\n",
    "\n",
    "    # --- Compute predicted flows using average parameters ---\n",
    "    predicted_flows_all_algorithms = {}\n",
    "    average_flows = {}  # to store final (padded) flows per algorithm\n",
    "    flow_lengths = []\n",
    "    max_total_flow = 0\n",
    "\n",
    "    # Use a publication-ready colormap for algorithm distinction.\n",
    "    algorithms = list(avg_df.index)\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    color_dict = {alg: cmap(i % 10) for i, alg in enumerate(algorithms)}\n",
    "\n",
    "    # First pass: compute flows and record lengths.\n",
    "    for algorithm in avg_df.index:\n",
    "        row = avg_df.loc[algorithm]\n",
    "        R1, T1, K1 = row['R1'], row['T1'], row['K1']\n",
    "        R2, T2, K2 = row['R2'], row['T2'], row['K2']\n",
    "        R3, T3, K3 = row['R3'], row['T3'], row['K3']\n",
    "\n",
    "        # Compute unit hydrograph ordinates (assumed to be defined externally)\n",
    "        uh1 = unit_hydrograph_ordinates(R1, T1, K1, delta_t)\n",
    "        uh2 = unit_hydrograph_ordinates(R2, T2, K2, delta_t)\n",
    "        uh3 = unit_hydrograph_ordinates(R3, T3, K3, delta_t)\n",
    "\n",
    "        # Convolve with rainfall (assumed external function)\n",
    "        Q1_inch_sec = hydrograph_convolution(uh1, rainfall)\n",
    "        Q2_inch_sec = hydrograph_convolution(uh2, rainfall)\n",
    "        Q3_inch_sec = hydrograph_convolution(uh3, rainfall)\n",
    "\n",
    "        # Convert to cfs\n",
    "        Q1_cfs = Q1_inch_sec * Area * 43560 / 12\n",
    "        Q2_cfs = Q2_inch_sec * Area * 43560 / 12\n",
    "        Q3_cfs = Q3_inch_sec * Area * 43560 / 12\n",
    "\n",
    "        total_flow = add_flow(Q1_cfs, Q2_cfs, Q3_cfs)\n",
    "        total_flow = np.array(total_flow)\n",
    "        predicted_flows_all_algorithms[algorithm] = total_flow\n",
    "        flow_lengths.append(len(total_flow))\n",
    "        max_total_flow = max(max_total_flow, np.max(total_flow))\n",
    "    \n",
    "    # Determine the maximum flow length\n",
    "    max_flow_length = max(flow_lengths)\n",
    "    \n",
    "    # Pad flows for each algorithm to the maximum length.\n",
    "    for algorithm in predicted_flows_all_algorithms:\n",
    "        flow = predicted_flows_all_algorithms[algorithm]\n",
    "        if len(flow) < max_flow_length:\n",
    "            flow = np.pad(flow, (0, max_flow_length - len(flow)), 'constant')\n",
    "        average_flows[algorithm] = flow\n",
    "        predicted_flows_all_algorithms[algorithm] = flow  # update stored value\n",
    "\n",
    "    # Build time axis in hours.\n",
    "    time_values = [i * delta_t / 3600 for i in range(max_flow_length)]\n",
    "    \n",
    "    # --- Compute the weighted flow ---\n",
    "    weights = Rank_weight.set_index('Algorithm')[weight_type].to_dict()\n",
    "    weighted_flow = np.zeros(max_flow_length)\n",
    "    for algorithm, avg_flow in average_flows.items():\n",
    "        weighted_flow += avg_flow * weights.get(algorithm, 0)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Plot average simulated RDII for each algorithm with markers and lines.\n",
    "    for algorithm, avg_flow in average_flows.items():\n",
    "        ax1.plot(time_values, avg_flow, label=f\"Avg. Sim. RDII ({algorithm})\", \n",
    "                 color=color_dict[algorithm], linestyle='-', marker='o', \n",
    "                 markersize=4, linewidth=1, markevery=5, alpha=0.7)\n",
    "    \n",
    "    # Plot weighted flow with distinct style and markers.\n",
    "    ax1.plot(time_values, weighted_flow, label=\"Weighted Sim. RDII\", \n",
    "             color='black', linestyle='-', marker='D', markersize=5, linewidth=2, markevery=10, alpha=0.9)\n",
    "    \n",
    "    metrics = None\n",
    "    final_weighted_score = None\n",
    "    if obs_rdii is not None:\n",
    "        n_sim = len(weighted_flow)\n",
    "        n_obs = len(obs_rdii)\n",
    "        n_final = max(n_sim, n_obs)\n",
    "        if n_sim < n_final:\n",
    "            weighted_flow = np.pad(weighted_flow, (0, n_final - n_sim), 'constant')\n",
    "        if n_obs < n_final:\n",
    "            obs_rdii = np.pad(obs_rdii, (0, n_final - n_obs), 'constant')\n",
    "        time_obs = [i * delta_t / 3600 for i in range(n_final)]\n",
    "        ax1.plot(time_obs, obs_rdii, label=\"Observed RDII\", color='green', \n",
    "                 linestyle='--', marker='^', markersize=6, linewidth=2, markevery=10)\n",
    "        metrics = calculate_metrics(weighted_flow, obs_rdii)\n",
    "        final_weighted_score = composite_score(metrics)\n",
    "        metrics_text = (\n",
    "            f\"RMSE: {metrics['RMSE']:.4f}\\n\"\n",
    "            f\"R²: {metrics['R2']:.4f}\\n\"\n",
    "            f\"PBIAS: {metrics['PBIAS']:.4f}%\\n\"\n",
    "            f\"NSE: {metrics['NSE']:.4f}\\n\"\n",
    "            f\"Performance Score: {final_weighted_score:.4f}\"\n",
    "        )\n",
    "        ax1.text(0.93, 0.68, metrics_text, transform=ax1.transAxes, fontsize=10,\n",
    "                 verticalalignment='top', horizontalalignment='right',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', edgecolor='black', alpha=0.8))\n",
    "    \n",
    "    # Plot rainfall as an inverted stem plot on a secondary y-axis.\n",
    "    ax2 = ax1.twinx()\n",
    "    rainfall_padded = np.pad(rainfall, (0, max_flow_length - len(rainfall)), 'constant')\n",
    "    time_rain = time_values\n",
    "    markerline, stemlines, baseline = ax2.stem(time_rain, rainfall_padded, \n",
    "                                               linefmt='blue', markerfmt=' ', basefmt=' ', label='Rainfall')\n",
    "    plt.setp(stemlines, 'color', 'blue', 'alpha', 0.5)\n",
    "    plt.setp(markerline, 'color', 'blue', 'alpha', 0.5)\n",
    "    ax2.set_ylim(0.9, 0)\n",
    "    \n",
    "    # Set y-limits and axis labels.\n",
    "    if obs_rdii is not None:\n",
    "        y_max = max(np.max(weighted_flow), np.max(obs_rdii) * 1.2)\n",
    "    else:\n",
    "        y_max = np.max(weighted_flow)\n",
    "    ax1.set_ylim(0, y_max)\n",
    "    plt.xlim(left=0)\n",
    "    \n",
    "    ax1.set_xlabel('Time (Hours)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('RDII (cfs)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Rainfall (in)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title(f'Weighted RDII Flow Validation (Weight Type: {weight_type})', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax1.legend(loc='upper right', bbox_to_anchor=(0.98, 0.98), fontsize=10, frameon=True)\n",
    "    ax2.legend(loc='upper right', bbox_to_anchor=(0.98, 0.70), fontsize=10, frameon=True)\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure if a plot name is provided.\n",
    "    if plot_name is not None:\n",
    "        fig.savefig(plot_name, format='png', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_flows_all_algorithms, weighted_flow, metrics, final_weighted_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
